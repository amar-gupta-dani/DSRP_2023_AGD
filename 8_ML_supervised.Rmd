---
title: "Lab8_ML2"
author: "Amar Dani"
date: "2023-07-17"
output: html_document
---
```{r setup}
library(dplyr)
library(reshape2)
library(ggplot2)
library(rsample)
library(parsnip)
library(ggthemes)
```
### Step 1: Collect Data
```{r}
head(iris)
```

### Step 2: Clean and Process Data
```{r}
no_NAs_sw <- filter(starwars, !is.na(mass), !is.na(height)) # Getting rid of NAs in the data and reducing # of cols

replaceWithMeans <- mutate(starwars,
                           mass = ifelse(is.na(mass),
                                         mean(mass),
                                         mass))
```

### Step 3: Visualize Data
Encode Categories as Factors/Integers. If categorical variable is already a factor, make it an integer
```{r}
intSpecies <- mutate(starwars, species = as.integer(as.factor(species)))
intSpecies
```
```{r}
irisAllNumeric <- mutate(iris, 
                         Species = as.integer((Species)))
irisAllNumeric
```
```{r}
irisCors <- cor(irisAllNumeric) |> melt() |> as.data.frame()

ggplot(irisCors, aes(x = Var1, y = Var2, fill=value)) + geom_tile() + scale_fill_gradient2(low = "orange", high ='blue', mid = 'white', midpoint = 0)
```
### Step 4: Perform Feature Selection
1. Choose which variables you want to classify or predict
2. Choose which variables you want to use as features in your model

For iris data: Classify on Species (Classification) & Predict on Sepal.Length (Regression)

### Step 5: Separate Data into Testing and Training Sets
```{r}
# Regression Dataset Splits

set.seed(71723) # set seed to produce same results

reg_split <- initial_split(irisAllNumeric, prop = .75) # Create a split with 75% of data for training

reg_train <- training(reg_split) # Creating dfs from split for training
reg_test <- testing(reg_split) # For testing
```

```{r}
# Classification Dataset Splits (use iris instead of irisAllNumeric)
class_split <- initial_split(iris, prop = .75) 

class_train <- training(class_split) # Creating dfs from split for training
class_test <- testing(class_split) # For testing
```

```{r}
reg_train
class_train
```
### Step 6 & 7: Choose an ML model 
```{r}
lm_fit <- linear_reg() |> set_engine("lm") |> set_mode("regression") |> fit(Sepal.Length ~ Petal.Length + Petal.Width + Species + Sepal.Width, data = reg_train) # Making ML model with an engine from the package "lm" and set to perform regression. We then fit the data to a fit. We can predict the Sepal length given the Petal width and length, Speices, and Sepal width. REMEMBER dataset must be TRAINING set. The function name is linear_reg()

lm_fit$fit # See the coefficients and intercept
summary(lm_fit$fit)
```
```{r}
binary_train_data <- filter(class_train, Species %in% c("setosa", "versicolor"))
binary_test_data <- filter(class_test, Species %in% c("setosa", "versicolor"))  # Filter data to 2 groups, then make variables factors, finally split into training and testing splits

log_fit <- logistic_reg() |> set_engine("glm") |> set_mode("classification") |> fit(Species ~ Petal.Width + Petal.Length + ., data = binary_train_data) # Logistic Regression is weird because it is classification. Only does 2 levels/groups. Use a period '.' to say "everything else". 

log_fit$fit
summary(log_fit$fit)
```

